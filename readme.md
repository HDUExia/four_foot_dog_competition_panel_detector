## 本Repo的用处
本Repo用于云深处的四足机器人比赛的仪表盘识别部分
本Repo修改自[yolov7](https://github.com/WongKinYiu/yolov7.git)与云深处[开源demo](https://github.com/OpenCVChina/DeepRobotDog.git)

CNN数据集取自自己队伍内拍摄与标注的数据集(这里就不放了)

## 优化思想

官方给的demo是传统识别。经过我们测试，发现传统识别在环境与光照条件复杂的区域ROI提取正确率较低，难以识别，鲁棒性较低。

考虑到比赛对正确性要求比较高，而不特别的看重识别速度，故我们计划采用CNN与传统识别结合的方式来提取识别仪表盘。

先使用CNN检测bbox提取ROI，再使用传统识别进行图像处理。神经网络端到端的方式可以很好的排除外部复杂的环境条件弥补传统识别对环境的要求。

由于我们CNN的数据集是各个角度的仪表盘，故神经网络会对仪表盘指针的指向特征不敏感，反而对仪表盘指针指向的颜色特征敏感。所以我们计划对提取的ROI来再进行一次传统识别的处理检测，这样的方式可以很好地弥补神经网络在外部光照条件改变的情况下对颜色的不鲁棒。



## 逻辑流程

本方案采用CNN与传统识别的方式去识别仪表盘。使用CNN提取仪表盘的ROI，然后丢入云深处的demo里识别。

如果传统识别结果与CNN分类一致，则输出分类结果。

如果不一致，则判断CNN出来的置信度。如果置信度大于一定阈值，则判断为本次检测结果不可靠，如果置信度小于阈值，则更相信传统识别的结果。

经测试,yolo框中的情况下识别正确率可达98%。yolo的ROI提取率可以调节参数来提高，或者另外训练模型。

流程图为`flowchart.drawio`

## 主要代码部分

`my_detect.py` line 137行后

权重模型为`best.pt`，好像github不能上传超过100M的文件，所以这东西放[网盘](https://pan.baidu.com/s/1opWls9q7pDpT8alZ3IzTdA?pwd=2023)了,提取码：2023

## 更多优化

推理代码修改自yolov7的detect.py。如果想部署到机械狗上，读者可以自行学习tensorrt框架来部署，C++推理快，python部署方便。由于本次准备比赛很仓促，就没部署，后面写完后会考虑把部署部分开源。

一开始考虑到主要目的是实现bbox的提取，所以打算采用速度和精度适中的模型yolov7-w6,使用的是tiny的参数。



## 环境配置

找到requirement.txt的目录

``````bash
pip install -r requirement.txt
#其他缺什么install什么就行了(应该)
#编写环境为
#ubuntu 20.04
#cuda 12.1(不知道python的需不需要这个)

#因为requirement.txt有很多不需要的东西，建议建个虚拟环境，到时候好删(python水平差，不知道删什么)
``````

核心推理部分为`my_detect.py`

## 写在后面

本人~~想收点star~~受RM开源氛围的影响，故会将一些比赛成果开源。本人用C++比较多，python水平较差，如果有错误，请友善交流🙏。~~对比赛有帮助麻烦给个star~~

手势识别就不放了，官方demo给的就是神经网络，调调参数就能用了，效果还不错。



## 关注HDU PHOENIX喵，关注HDU PHOENIX谢谢喵。

